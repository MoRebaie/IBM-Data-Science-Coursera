{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda/envs/Python36\n",
      "\n",
      "  added / updated specs: \n",
      "    - geopy\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2019.11.28 |       hecc5488_0         145 KB  conda-forge\n",
      "    certifi-2019.11.28         |           py36_0         149 KB  conda-forge\n",
      "    geographiclib-1.50         |             py_0          34 KB  conda-forge\n",
      "    openssl-1.1.1d             |       h516909a_0         2.1 MB  conda-forge\n",
      "    geopy-1.20.0               |             py_0          57 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         2.5 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "    geographiclib:   1.50-py_0         conda-forge\n",
      "    geopy:           1.20.0-py_0       conda-forge\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "    ca-certificates: 2019.10.16-0                  --> 2019.11.28-hecc5488_0 conda-forge\n",
      "    certifi:         2019.9.11-py36_0              --> 2019.11.28-py36_0     conda-forge\n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "    openssl:         1.1.1d-h7b6447c_3             --> 1.1.1d-h516909a_0     conda-forge\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "ca-certificates-2019 | 145 KB    | ##################################### | 100% \n",
      "certifi-2019.11.28   | 149 KB    | ##################################### | 100% \n",
      "geographiclib-1.50   | 34 KB     | ##################################### | 100% \n",
      "openssl-1.1.1d       | 2.1 MB    | ##################################### | 100% \n",
      "geopy-1.20.0         | 57 KB     | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda/envs/Python36\n",
      "\n",
      "  added / updated specs: \n",
      "    - folium=0.5.0\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    folium-0.5.0               |             py_0          45 KB  conda-forge\n",
      "    branca-0.3.1               |             py_0          25 KB  conda-forge\n",
      "    altair-3.3.0               |           py36_0         747 KB  conda-forge\n",
      "    vincent-0.4.4              |             py_1          28 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         846 KB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "    altair:  3.3.0-py36_0 conda-forge\n",
      "    branca:  0.3.1-py_0   conda-forge\n",
      "    folium:  0.5.0-py_0   conda-forge\n",
      "    vincent: 0.4.4-py_1   conda-forge\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "folium-0.5.0         | 45 KB     | ##################################### | 100% \n",
      "branca-0.3.1         | 25 KB     | ##################################### | 100% \n",
      "altair-3.3.0         | 747 KB    | ##################################### | 100% \n",
      "vincent-0.4.4        | 28 KB     | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Libraries are imported.\n"
     ]
    }
   ],
   "source": [
    "# importing libraries\n",
    "import numpy as np # library to handle data in a vectorized manner\n",
    "import pandas as pd # library for data analsysis\n",
    "from bs4 import BeautifulSoup\n",
    "import requests # library to handle requests\n",
    "import json # library to handle JSON files\n",
    "from pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "!conda install -c conda-forge geopy --yes # uncomment this line if you haven't completed the Foursquare API lab\n",
    "import geopy.geocoders # convert an address into latitude and longitude values\n",
    "\n",
    "!conda install -c conda-forge folium=0.5.0 --yes # uncomment this line if you haven't completed the Foursquare API lab\n",
    "import folium # map rendering library\n",
    "\n",
    "print('Libraries are imported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset which is about postal codes in Toronto\n",
    "# This dataset was created in week 3. \n",
    "df_toronto = pd.read_csv('toronto_base.csv')\n",
    "df_toronto.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the city Toronto, latitude and longtitude are manually extracted via google search\n",
    "toronto_latitude = 43.6932; toronto_longitude = -79.3832\n",
    "map_toronto = folium.Map(location = [toronto_latitude, toronto_longitude], zoom_start = 10.7)\n",
    "\n",
    "# add markers to map\n",
    "for lat, lng, borough, neighborhood in zip(df_toronto['Latitude'], df_toronto['Longitude'], df_toronto['Borough'], df_toronto['Neighbourhood']):\n",
    "    label = '{}, {}'.format(neighborhood, borough)\n",
    "    label = folium.Popup(label, parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lng],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color='blue',\n",
    "        fill=True,\n",
    "        fill_color='#3186cc',\n",
    "        fill_opacity=0.7).add_to(map_toronto)  \n",
    "    \n",
    "\n",
    "map_toronto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df_toronto['Borough'] == 'Scarborough'\n",
    "\n",
    "# selecting only neighborhoods regarding to \"Scarborough\" borough.\n",
    "scarborough_data = df_toronto[df_toronto['Borough'] == 'Scarborough']\n",
    "scarborough_data = scarborough_data.reset_index(drop=True).drop(columns = 'Unnamed: 0')\n",
    "scarborough_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_scar = 'Scarborough, Toronto'\n",
    "latitude_scar = 43.773077\n",
    "longitude_scar = -79.257774\n",
    "print('The geograpical coordinate of \"Scarborough\" are: {}, {}.'.format(latitude_scar, longitude_scar))\n",
    "\n",
    "map_Scarborough = folium.Map(location=[latitude_scar, longitude_scar], zoom_start=11.5)\n",
    "\n",
    "# add markers to map\n",
    "for lat, lng, label in zip(scarborough_data['Latitude'], scarborough_data['Longitude'], scarborough_data['Neighbourhood']):\n",
    "    label = folium.Popup(label, parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lng],\n",
    "        radius = 10,\n",
    "        popup = label,\n",
    "        color ='blue',\n",
    "        fill = True,\n",
    "        fill_color = '#3186cc',\n",
    "        fill_opacity = 0.7).add_to(map_Scarborough)  \n",
    "    \n",
    "map_Scarborough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foursquare_crawler (postal_code_list, neighborhood_list, lat_list, lng_list, LIMIT = 500, radius = 1000):\n",
    "    result_ds = []\n",
    "    counter = 0\n",
    "    for postal_code, neighborhood, lat, lng in zip(postal_code_list, neighborhood_list, lat_list, lng_list):\n",
    "         \n",
    "        # create the API request URL\n",
    "        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "            CLIENT_ID, CLIENT_SECRET, VERSION, \n",
    "            lat, lng, radius, LIMIT)\n",
    "            \n",
    "        # make the GET request\n",
    "        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n",
    "        tmp_dict = {}\n",
    "        tmp_dict['Postal Code'] = postal_code; tmp_dict['Neighborhood(s)'] = neighborhood; \n",
    "        tmp_dict['Latitude'] = lat; tmp_dict['Longitude'] = lng;\n",
    "        tmp_dict['Crawling_result'] = results;\n",
    "        result_ds.append(tmp_dict)\n",
    "        counter += 1\n",
    "        print('{}.'.format(counter))\n",
    "        print('Data is Obtained, for the Postal Code {} (and Neighborhoods {}) SUCCESSFULLY.'.format(postal_code, neighborhood))\n",
    "    return result_ds;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @hiddel_cell\n",
    "CLIENT_ID = '0UOOVVQUXZTSOJ5302UDTB1L500GIY0RCTXSTUJYXUIFGJXG' # your Foursquare ID\n",
    "CLIENT_SECRET = 'IBQQ0QYDBQCBCDZ3QBRSVC1JWKU0HGMIIMDVM4DOJW34RGAB' # your Foursquare Secret\n",
    "VERSION = '20180605' # Foursquare API version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Crawling different neighborhoods inside \"Scarborough\"')\n",
    "Scarborough_foursquare_dataset = foursquare_crawler(list(scarborough_data['Postcode']),\n",
    "                                                   list(scarborough_data['Neighbourhood']),\n",
    "                                                   list(scarborough_data['Latitude']),\n",
    "                                                   list(scarborough_data['Longitude']),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"Scarborough_foursquare_dataset.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(Scarborough_foursquare_dataset, fp)\n",
    "print('Received Data from Internet is Saved to Computer.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Scarborough_foursquare_dataset.txt\", \"rb\") as fp:   # Unpickling\n",
    "    Scarborough_foursquare_dataset = pickle.load(fp)\n",
    "# print(type(Scarborough_foursquare_dataset))\n",
    "# Scarborough_foursquare_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is created to connect to the saved list which is the received database. It will extract each venue \n",
    "# for every neighborhood inside the database\n",
    "\n",
    "def get_venue_dataset(foursquare_dataset):\n",
    "    result_df = pd.DataFrame(columns = ['Postal Code', 'Neighborhood', \n",
    "                                           'Neighborhood Latitude', 'Neighborhood Longitude',\n",
    "                                          'Venue', 'Venue Summary', 'Venue Category', 'Distance'])\n",
    "    # print(result_df)\n",
    "    \n",
    "    for neigh_dict in foursquare_dataset:\n",
    "        postal_code = neigh_dict['Postal Code']; neigh = neigh_dict['Neighborhood(s)']\n",
    "        lat = neigh_dict['Latitude']; lng = neigh_dict['Longitude']\n",
    "        print('Number of Venuse in Coordination \"{}\" Posal Code and \"{}\" Negihborhood(s) is:'.format(postal_code, neigh))\n",
    "        print(len(neigh_dict['Crawling_result']))\n",
    "        \n",
    "        for venue_dict in neigh_dict['Crawling_result']:\n",
    "            summary = venue_dict['reasons']['items'][0]['summary']\n",
    "            name = venue_dict['venue']['name']\n",
    "            dist = venue_dict['venue']['location']['distance']\n",
    "            cat =  venue_dict['venue']['categories'][0]['name']\n",
    "            \n",
    "            \n",
    "            # print({'Postal Code': postal_code, 'Neighborhood': neigh, \n",
    "            #                   'Neighborhood Latitude': lat, 'Neighborhood Longitude':lng,\n",
    "            #                   'Venue': name, 'Venue Summary': summary, \n",
    "            #                   'Venue Category': cat, 'Distance': dist})\n",
    "            \n",
    "            result_df = result_df.append({'Postal Code': postal_code, 'Neighborhood': neigh, \n",
    "                              'Neighborhood Latitude': lat, 'Neighborhood Longitude':lng,\n",
    "                              'Venue': name, 'Venue Summary': summary, \n",
    "                              'Venue Category': cat, 'Distance': dist}, ignore_index = True)\n",
    "            # print(result_df)\n",
    "    \n",
    "    return(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scarborough_venues = get_venue_dataset(Scarborough_foursquare_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scarborough_venues.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scarborough_venues.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scarborough_venues.to_csv('scarborough_venues.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scarborough_venues = pd.read_csv('scarborough_venues.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh_list = list(scarborough_venues['Neighborhood'].unique())\n",
    "print('Number of Neighborhoods inside Scarborough:')\n",
    "print(len(neigh_list))\n",
    "print('List of Neighborhoods inside Scarborough:')\n",
    "neigh_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh_venue_summary = scarborough_venues.groupby('Neighborhood').count()\n",
    "neigh_venue_summary.drop(columns = ['Unnamed: 0']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are {} uniques categories.'.format(len(scarborough_venues['Venue Category'].unique())))\n",
    "\n",
    "print('Here is the list of different categories:')\n",
    "list(scarborough_venues['Venue Category'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for fun and deeper understanding\n",
    "print(type(scarborough_venues[['Venue Category']]))\n",
    "\n",
    "print(type(scarborough_venues['Venue Category']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "scarborough_onehot = pd.get_dummies(data = scarborough_venues, drop_first  = False, \n",
    "                              prefix = \"\", prefix_sep = \"\", columns = ['Venue Category'])\n",
    "scarborough_onehot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This list is created manually \n",
    "important_list_of_features = [\n",
    " \n",
    " 'Neighborhood',\n",
    " 'Neighborhood Latitude',\n",
    " 'Neighborhood Longitude',\n",
    "\n",
    " 'African Restaurant',\n",
    " 'American Restaurant',\n",
    " 'Asian Restaurant',\n",
    "\n",
    " \n",
    " 'BBQ Joint',\n",
    " \n",
    " 'Bakery',\n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " 'Breakfast Spot',\n",
    "\n",
    " 'Burger Joint',\n",
    " \n",
    " \n",
    " \n",
    " 'Cajun / Creole Restaurant',\n",
    " 'Cantonese Restaurant',\n",
    " 'Caribbean Restaurant',\n",
    " 'Chinese Restaurant',\n",
    " \n",
    " 'Diner',\n",
    "\n",
    "\n",
    " 'Fast Food Restaurant',\n",
    " 'Filipino Restaurant',\n",
    " 'Fish Market',\n",
    " 'Food & Drink Shop',\n",
    " 'Fried Chicken Joint',\n",
    " 'Fruit & Vegetable Store',\n",
    " \n",
    " 'Greek Restaurant',\n",
    " 'Grocery Store',\n",
    " \n",
    " 'Hakka Restaurant',\n",
    " \n",
    " 'Hong Kong Restaurant',\n",
    "\n",
    " 'Hotpot Restaurant',\n",
    " \n",
    " 'Indian Restaurant',\n",
    "\n",
    " 'Italian Restaurant',\n",
    " 'Japanese Restaurant',\n",
    " 'Korean Restaurant',\n",
    " 'Latin American Restaurant',\n",
    "\n",
    "\n",
    "\n",
    " 'Malay Restaurant',\n",
    " \n",
    " 'Mediterranean Restaurant',\n",
    " \n",
    " 'Mexican Restaurant',\n",
    " 'Middle Eastern Restaurant',\n",
    " \n",
    " 'Noodle House',\n",
    " \n",
    " 'Pizza Place',\n",
    " \n",
    " 'Restaurant',\n",
    " 'Sandwich Place',\n",
    " 'Seafood Restaurant',\n",
    " 'Shanghai Restaurant',\n",
    " \n",
    " 'Sushi Restaurant',\n",
    " 'Taiwanese Restaurant',\n",
    " \n",
    " 'Thai Restaurant',\n",
    " \n",
    " 'Vegetarian / Vegan Restaurant',\n",
    " \n",
    " 'Vietnamese Restaurant',\n",
    " 'Wings Joint']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    columns = ['Neighborhood Latitude', 'Neighborhood Longitude']).groupby(\n",
    "    'Neighborhood').sum()\n",
    "\n",
    "\n",
    "scarborough_onehot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_name_list = list(scarborough_onehot.columns)\n",
    "restaurant_list = []\n",
    "\n",
    "\n",
    "for counter, value in enumerate(feat_name_list):\n",
    "    if value.find('Restaurant') != (-1):\n",
    "        restaurant_list.append(value)\n",
    "        \n",
    "scarborough_onehot['Total Restaurants'] = scarborough_onehot[restaurant_list].sum(axis = 1)\n",
    "scarborough_onehot = scarborough_onehot.drop(columns = restaurant_list)\n",
    "\n",
    "\n",
    "feat_name_list = list(scarborough_onehot.columns)\n",
    "joint_list = []\n",
    "\n",
    "\n",
    "for counter, value in enumerate(feat_name_list):\n",
    "    if value.find('Joint') != (-1):\n",
    "        joint_list.append(value)\n",
    "        \n",
    "scarborough_onehot['Total Joints'] = scarborough_onehot[joint_list].sum(axis = 1)\n",
    "scarborough_onehot = scarborough_onehot.drop(columns = joint_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scarborough_onehot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import k-means from clustering stage\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# run k-means clustering\n",
    "kmeans = KMeans(n_clusters = 5, random_state = 0).fit(scarborough_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_df = pd.DataFrame(kmeans.cluster_centers_)\n",
    "means_df.columns = scarborough_onehot.columns\n",
    "means_df.index = ['G1','G2','G3','G4','G5']\n",
    "means_df['Total Sum'] = means_df.sum(axis = 1)\n",
    "means_df.sort_values(axis = 0, by = ['Total Sum'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh_summary = pd.DataFrame([scar_ds.index, 1 + kmeans.labels_]).T\n",
    "neigh_summary.columns = ['Neighborhood', 'Group']\n",
    "neigh_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh_summary[neigh_summary['Group'] == 5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_of_neigh = list(neigh_summary[neigh_summary['Group'] == 5]['Neighborhood'])[0]\n",
    "scarborough_venues[scarborough_venues['Neighborhood'] == name_of_neigh].iloc[0,1:5].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh_summary[neigh_summary['Group'] == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh_summary[neigh_summary['Group'] == 4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_of_neigh = list(neigh_summary[neigh_summary['Group'] == 4]['Neighborhood'])[0]\n",
    "scarborough_venues[scarborough_venues['Neighborhood'] == name_of_neigh].iloc[0,1:5].to_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
